%!TEX root = kotov.tex
\section{Task 3: Насколько сжатие путей быстрое?}
\begin{task}
    Доказать, что СНМ с одной эвристикой сжатия пути, к которому поступают следующие запросы <<сперва только join-ы вида $p[\texttt{root}] = \texttt{x}$ (где \texttt{root} --- именно корень, а \texttt{x} --- любая вершина другого множества), затем только get-ы>>, работает за $\O(n + m)$, где $n$ --- число элементов, $m$ --- суммарное число запросов.
\end{task}

\begin{solution}
    Пусть у нам пришло $m_1$ запросов на \texttt{join}, тогда за $\O(m_1)$ мы выполним формальное подвешивание поддеревьев к каким-то вершинами из запроса (банально, это \texttt{Node} с указателями) в итоге получим какой-то лес, в общем случае, но давайте не умаляя общности считать, что получили одно дерево, так как запросы \texttt{get} работают в рамках одного дерева.

    % Рассмотрим самый идеальный вариант: все вершинки подвесились к одному и тому же корню, тогда на запросы \texttt{get} мы отвечаем за $\O(1)$, всего будет $m_2$ таких запросов, следовательно всего потратим $\O(m_2)$ на все ответы. Суммарно получили $\O(m)$.

    Представим, что пришел запрос на элемент $x$, который находится на глубине $h_x$. Тогда для него мы ответим за $\O(h_x)$, после чего для всех вершин-предков (т.е. предков, предков предков и т. д. до корня) мы сможем отвечать моментально (т.к. их глубина стала равна $1$), а глубина всех вершин, что глубже $x$, уменьшилась на $h_x$. Рассмотрим самый грустный вариант, когда у нас есть бамбук: самым тяжелым ответом будет \texttt{get} последнего элемента ($\O(n)$), зато все остальные будут за $\O(1)$ после этого. Если какой-то промежуточный, то мы бы ответили за $\O(h_x)$ для него, но тогда самым тяжелым после этого стал бы запрос \texttt{get} на последний элемент, у которого глубина уже $\O(n - h_x)$, в итоге мы бы потратили $\O(h_x + n - h_x) = \O(n)$, на такую обработку, и можем считать, что на сам формальный ответ на запрос тратим $\O(1)$. Стоит еще заметить, что глубина любой вершины не может быть больше $n$, а после обработки вершины с глубиной $h_x$, не глубина любой вершины не больше $n - h_x$ (банально, не хватит вершин, чтобы так глубоко можно было бы уйти).

    \begin{remark}
        То есть в каком-то смысле если бы запросы приходили в порядке углубления элементов, а последний запрос был бы как раз на самый глубокий элемент, то мы бы потратили как раз $\O(n + m_2)$ времени на это. То есть так или иначе, если нам надо отвечать на самый глубокий элемент, то мы неизбежно тратим $\O(n)$, важно, что если мы не сразу к нему обращаемся, то легче (в плане суммарно легче) нам не становится, потому что мы так или иначе до него все равно доберемся, просто потратим кусочки работы не сразу на нем, а на другим элементах повыше (я честно пытался это написать понятно).
    \end{remark}

    Об этом еще можно думать в терминах количества переподвешенных вершин, т.к. мы каждую вершину мы можем переподвесить не более одного раза, допустим, при обработке вершины мы переподвесили $k$ вершин (что на самом деле значит, что ее глубина $k$), осталось $n-k$ непереподвешенных вершин, но всего-то вершин $n$, следовательно на эти операции мы в худшем случае потратим $\O(n)$, а на формальный ответ можем считать, что тратим $\O(1)$, т.к. сжатие мы посчитали отдельно. В итоге получатся сложность $\O(n + m)$
\end{solution}