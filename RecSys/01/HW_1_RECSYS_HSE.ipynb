{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матричные факторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе вам предстоит познакомиться с практической стороной матричных разложений.\n",
    "Работа поделена на 4 задания:\n",
    "1. Вам необходимо реализовать SVD разложения используя SGD на explicit данных\n",
    "2. Вам необходимо реализовать матричное разложения используя ALS на implicit данных\n",
    "3. Вам необходимо реализовать матричное разложения используя BPR на implicit данных\n",
    "4. Вам необходимо реализовать матричное разложения используя WARP на implicit данных\n",
    "\n",
    "Мягкий дедлайн 13 Октября (пишутся замечания, выставляется оценка, есть возможность исправить до жесткого дедлайна)\n",
    "\n",
    "Жесткий дедлайн 20 Октября (Итоговая проверка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from lightfm.datasets import fetch_movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе мы будем работать с explicit датасетом movieLens, в котором представленны пары user_id movie_id и rating выставленный пользователем фильму\n",
    "\n",
    "Скачать датасет можно по ссылке https://grouplens.org/datasets/movielens/1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-1m/ratings.dat', delimiter='::', header=None, \n",
    "        names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
    "        usecols=['user_id', 'movie_id', 'rating'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info = pd.read_csv('ml-1m/movies.dat', delimiter='::', header=None, \n",
    "        names=['movie_id', 'name', 'category'], engine='python', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы преобразовать текущий датасет в Implicit, давайте считать что позитивная оценка это оценка >=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_ratings = ratings.loc[(ratings['rating'] >= 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удобнее работать с sparse матричками, давайте преобразуем DataFrame в CSR матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = implicit_ratings[\"user_id\"]\n",
    "movies = implicit_ratings[\"movie_id\"]\n",
    "user_item = sp.coo_matrix((np.ones_like(users), (users, movies)))\n",
    "user_item_t_csr = user_item.T.tocsr()\n",
    "user_item_csr = user_item.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера воспользуемся ALS разложением из библиотеки implicit\n",
    "\n",
    "Зададим размерность латентного пространства равным 64, это же определяет размер user/item эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=64, iterations=100, calculate_training_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве loss здесь всеми любимый RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(user_item_t_csr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим похожие фильмы по 1 movie_id = Истории игрушек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similars = lambda item_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() for x in model.similar_items(item_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similar_items(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, симилары действительно оказались симиларами.\n",
    "\n",
    "Качество симиларов часто является хорошим способом проверить качество алгоритмов.\n",
    "\n",
    "P.S. Если хочется поглубже разобраться в том как разные алгоритмы формируют разные латентные пространства, рекомендую загружать полученные вектора в tensorBoard и смотреть на сформированное пространство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similars(1, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь построим рекомендации для юзеров\n",
    "\n",
    "Как мы видим юзеру нравится фантастика, значит и в рекомендациях ожидаем увидеть фантастику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_history = lambda user_id, implicit_ratings : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string() for x in implicit_ratings[implicit_ratings[\"user_id\"] == user_id][\"movie_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_history(4, implicit_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось! \n",
    "\n",
    "Мы действительно порекомендовали пользователю фантастику и боевики, более того встречаются продолжения тех фильмов, которые он высоко оценил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations = lambda user_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                               for x in model.recommend(user_id, user_item_csr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations(4, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь ваша очередь реализовать самые популярные алгоритмы матричных разложений\n",
    "\n",
    "Что будет оцениваться:\n",
    "1. Корректность алгоритма\n",
    "2. Качество получившихся симиларов\n",
    "3. Качество итоговых рекомендаций для юзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factorization import SVD, SVDS\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similars = lambda item_id, model : movie_info[movie_info[\"movie_id\"].isin(model.similar_items(item_id))][[\"name\", \"category\"]]\n",
    "\n",
    "get_recommendations = lambda user_id, model : movie_info[movie_info[\"movie_id\"].isin(model.recommend(user_id))][[\"name\", \"category\"]]\n",
    "\n",
    "get_user_history = lambda user_id, implicit_ratings : movie_info[movie_info[\"movie_id\"].isin(implicit_ratings[implicit_ratings[\"user_id\"] == user_id][\"movie_id\"])][[\"name\", \"category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    item_id = 1\n",
    "    target = movie_info[movie_info.movie_id == item_id]\n",
    "    print(f\"Similar to {target.name.item()} ({target.category.item()}):\")\n",
    "    sims = model.similar_items(item_id)\n",
    "    \n",
    "    for idx, i in enumerate(sims):\n",
    "        selected = movie_info[movie_info.movie_id == i]\n",
    "        print(f\"{idx + 1}) {selected.name.item()} ({selected.category.item()})\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    user_id = 4\n",
    "    print(f\"Recommended movies for user {user_id}:\")\n",
    "    recs = model.recommend(user_id)\n",
    "    \n",
    "    for idx, i in enumerate(recs):\n",
    "        selected = movie_info[movie_info.movie_id == i]\n",
    "        if len(selected) != 0:\n",
    "            print(f\"{idx + 1}) {selected.name.item()} ({selected.category.item()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1. Не использую готовые решения, реализовать SVD разложение используя SGD на explicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_exp = sp.coo_matrix((ratings[\"rating\"], (ratings[\"user_id\"], ratings[\"movie_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_svd = SVD(64, iterations=1000, lr=1e-4, verbose=True, weight_decay=1e-2)\n",
    "model_svd.fit(user_item_exp)  \n",
    "\n",
    "timestamp = datetime.now()\n",
    "model_svd.logger.save(f\"log.{timestamp.date()}_{timestamp.time()}.csv\")\n",
    "model_svd.logger.plot(\"iter\", \"rmse\", label=\"RMSE\", x_label=\"Iteration\", y_label=\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(model_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_svds = SVDS(64, iterations=50, lr=1e-2, verbose=True, weight_decay=1e-2, save_every=10)\n",
    "\n",
    "model_svds.fit(user_item_exp)\n",
    "\n",
    "timestamp = datetime.now()\n",
    "model_svds.logger.save(f\"log.{timestamp.date()}_{timestamp.time()}.csv\")\n",
    "model_svds.logger.plot(\"iter\", \"rmse\", label=\"RMSE\", x_label=\"Iteration\", y_label=\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(model_svds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Не использую готовые решения, реализовать матричное разложение используя ALS на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factorization import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_als = ALS(64, 10, 1e-5, 1e-5, True)\n",
    "\n",
    "model_als.fit(user_item_csr)\n",
    "\n",
    "timestamp = datetime.now()\n",
    "model_als.logger.save(f\"log.{timestamp.date()}_{timestamp.time()}.csv\")\n",
    "model_als.logger.plot(\"iter\", \"rmse\", label=\"RMSE\", x_label=\"Iteration\", y_label=\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(model_als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Не использую готовые решения, реализовать матричное разложение BPR на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factorization import BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_bpr = BPR(64, int(1e4), 1e-1, 1e-2, True, save_every=500)\n",
    "\n",
    "model_bpr.fit(user_item_csr, batch_size=3000)\n",
    "\n",
    "timestamp = datetime.now()\n",
    "model_bpr.logger.save(f\"log.{timestamp.date()}_{timestamp.time()}.csv\")\n",
    "model_bpr.logger.plot(\"iter\", \"AUC\", label=\"AUC\", x_label=\"Iteration\", y_label=\"AUC\")\n",
    "model_bpr.logger.plot(\"iter\", \"AUC2\", label=\"AUC2\", x_label=\"Iteration\", y_label=\"AUC2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(model_bpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4. Не использую готовые решения, реализовать матричное разложение WARP на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model_svds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model_als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model_bpr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58f4131e16bae183d805153abd4d758d37eefdecf8ebf14c2d1024a16030191c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ml': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
