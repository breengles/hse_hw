{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd071f4a8a05e914619e6ce849cc212b7860cf82baee4b36c2033f2d6275d70daac",
   "display_name": "Python 3.8.5 64-bit ('ml': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 100\n",
    "PRINT_EVERY = NUM_EPOCHS // 100 if NUM_EPOCHS > 100 else 1\n",
    "TEACHER_PATH = \"./teacher.pth\"\n",
    "LR = 0.01\n",
    "NUM_WORKERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(net, loader):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            \n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            outputs = net(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    net.train()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                     std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=NUM_WORKERS)\n",
    "testloader = torch.utils.data.DataLoader(testset, \n",
    "                                         batch_size=BATCH_SIZE, \n",
    "                                         shuffle=False, \n",
    "                                         num_workers=NUM_WORKERS)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = models.vgg16_bn(pretrained=True)\n",
    "\n",
    "# for param in teacher.features.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "teacher.classifier[6] = nn.Linear(4096,10)\n",
    "\n",
    "# teacher.classifier[6] = nn.Linear(4096,1024)\n",
    "# teacher.classifier.add_module(\"head\", nn.Linear(1024, 10))\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(teacher.parameters(), lr=LR, momentum=0.9)\n",
    "# optimizer = optim.Adam(teacher.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded saved teacher model\n"
     ]
    }
   ],
   "source": [
    "if not path.exists(TEACHER_PATH):\n",
    "    t = tqdm(range(NUM_EPOCHS))\n",
    "    teacher.to(DEVICE)\n",
    "    for epoch in t:\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = teacher(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % PRINT_EVERY == 0:\n",
    "            acc = get_acc(teacher, testloader)\n",
    "            print(f'[{epoch + 1}] loss: {running_loss / len(trainloader):0.9f} | accuracy: {acc:0.2f}%')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    torch.save(teacher.state_dict(), TEACHER_PATH)\n",
    "else:\n",
    "    print(\"Loaded saved teacher model\")\n",
    "    teacher.load_state_dict(torch.load(TEACHER_PATH))\n",
    "    teacher.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "134309962\n"
     ]
    }
   ],
   "source": [
    "TEACHER_NUM_PARAMS = sum(p.numel() for p in teacher.parameters())\n",
    "print(TEACHER_NUM_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 90.03 %\n"
     ]
    }
   ],
   "source": [
    "TEACHER_ACC = get_acc(teacher, testloader)\n",
    "print(f\"Accuracy: {TEACHER_ACC} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy for class plane is: 92.8\nAccuracy for class car is: 94.6\nAccuracy for class bird is: 87.3\nAccuracy for class cat is: 77.9\nAccuracy for class deer is: 89.6\nAccuracy for class dog is: 82.9\nAccuracy for class frog is: 93.0\nAccuracy for class horse is: 92.0\nAccuracy for class ship is: 94.7\nAccuracy for class truck is: 92.4\n"
     ]
    }
   ],
   "source": [
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data    \n",
    "        outputs = teacher(images.to(DEVICE))    \n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        for label, prediction in zip(labels, predictions.cpu()):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "  \n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f\"Accuracy for class {classname} is: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dVGG(nn.Module):\n",
    "    def __init__(self, a=0, kind=1):\n",
    "        super().__init__()\n",
    "        self.one = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(16 * 5 * 5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "        self.two = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(16 * 10 * 10, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "        self.three = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(),\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.Conv2d(256, 512, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.BatchNorm2d(512),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "        \n",
    "        self.criterion_mse = torch.nn.MSELoss()\n",
    "        self.criterion_ce = torch.nn.CrossEntropyLoss()\n",
    "        self.a = a\n",
    "        self.kind = kind\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.kind == 1:\n",
    "            out = self.one(x)\n",
    "        elif self.kind == 2:\n",
    "            out = self.two(x)\n",
    "        elif self.kind == 3:\n",
    "            out = self.three(x)\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected `kind`\")\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def loss(self, output, teacher_prob, real_label):\n",
    "        return self.a * self.criterion_ce(output, real_label) + (1 - self.a) * self.criterion_mse(output, teacher_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline(kind=3, opt=\"sgd\", coef=1):\n",
    "    print(f\"=== {kind} | {opt} ===\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    net = dVGG(1, kind).to(DEVICE)\n",
    "    \n",
    "    if opt.lower() == \"sgd\":\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "    if opt.lower() == \"adam\":\n",
    "        optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "\n",
    "    if not path.exists(f\"baseline_{kind}_{opt}.pth\"):\n",
    "        for epoch in tqdm(range(int(NUM_EPOCHS * coef))):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader):\n",
    "                inputs, labels = data\n",
    "                \n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "            if (epoch + 1) % PRINT_EVERY == 0:\n",
    "                acc = get_acc(net, testloader)\n",
    "                print(f'[{epoch + 1}] loss: {running_loss / len(trainloader):0.5f} | accuracy: {acc:0.2f}%')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        torch.save(net.state_dict(), f\"./baseline_{kind}_{opt}.pth\")\n",
    "        print(f\"=== Finished: {kind} | {opt} ===\")\n",
    "    else:\n",
    "        print(\"Loaded saved baseline model\")\n",
    "        net.load_state_dict(torch.load(f\"baseline_{kind}_{opt}.pth\"))\n",
    "        net.to(DEVICE)\n",
    "\n",
    "    baseline_acc = get_acc(net, testloader)\n",
    "\n",
    "    print(\"Baseline accuracy on test:\", baseline_acc, \"%\")\n",
    "    return baseline_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distil(a=0, kind=3, opt=\"sgd\", coef=1):\n",
    "    print(f\"=== {a} | {kind} | {opt} ===\")\n",
    "    net = dVGG(a, kind).to(DEVICE)\n",
    "    if opt.lower() == \"sgd\":\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "    if opt.lower() == \"adam\":\n",
    "        optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "\n",
    "    for epoch in tqdm(range(int(NUM_EPOCHS * coef))):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            \n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs_teacher = teacher(inputs)\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = net.loss(outputs, outputs_teacher, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        if (epoch + 1) % PRINT_EVERY == 0:\n",
    "            acc = get_acc(net, testloader)\n",
    "            print(f'[{epoch + 1}] loss: {running_loss / len(trainloader):0.5f} | accuracy: {acc:0.2f}%')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    learner_acc = get_acc(net, testloader)\n",
    "    torch.save(net.state_dict(), f\"./distilled_{a}_{kind}_{opt}.pth\")\n",
    "\n",
    "    learner_num_params = sum(p.numel() for p in net.parameters())\n",
    "    print(f\"=== Finished: {a} | {kind} | {opt} ===\")\n",
    "    print(\"\\tTotal number of teacher params:\", TEACHER_NUM_PARAMS)\n",
    "    print(\"\\tTotal number of learner params:\", learner_num_params)\n",
    "    print(\"\\tTotal reduction:\", (TEACHER_NUM_PARAMS - learner_num_params) / TEACHER_NUM_PARAMS * 100, \"%\")\n",
    "    print(\"\\tTeacher  accuracy on test:\", TEACHER_ACC, \"%\")\n",
    "    print(\"\\tLearner  accuracy on test:\", learner_acc, \"%\")\n",
    "    print(\"\\tBaseline accuracy on test:\", BASELINE_ACC, \"%\")\n",
    "    print(\"\\tDiff:\", TEACHER_ACC - learner_acc, learner_acc - BASELINE_ACC)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== 3 | sgd ===\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb8b47250b9c48da8f769fcf62c13b38"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1] loss: 2.11921 | accuracy: 12.37%\n",
      "[2] loss: 1.69053 | accuracy: 21.20%\n",
      "[3] loss: 1.47043 | accuracy: 33.19%\n",
      "[4] loss: 1.33389 | accuracy: 43.50%\n",
      "[5] loss: 1.22507 | accuracy: 50.28%\n",
      "[6] loss: 1.14128 | accuracy: 50.79%\n",
      "[7] loss: 1.07695 | accuracy: 55.64%\n",
      "[8] loss: 1.01381 | accuracy: 61.05%\n",
      "[9] loss: 0.96132 | accuracy: 62.05%\n",
      "[10] loss: 0.91014 | accuracy: 66.29%\n",
      "[11] loss: 0.86752 | accuracy: 68.11%\n",
      "[12] loss: 0.83093 | accuracy: 70.35%\n",
      "[13] loss: 0.79132 | accuracy: 71.68%\n",
      "[14] loss: 0.75736 | accuracy: 71.47%\n",
      "[15] loss: 0.73473 | accuracy: 71.54%\n",
      "[16] loss: 0.70967 | accuracy: 73.56%\n",
      "[17] loss: 0.68172 | accuracy: 74.61%\n",
      "[18] loss: 0.65627 | accuracy: 76.05%\n",
      "[19] loss: 0.63578 | accuracy: 76.59%\n",
      "[20] loss: 0.62276 | accuracy: 75.67%\n",
      "[21] loss: 0.59852 | accuracy: 76.78%\n",
      "[22] loss: 0.58718 | accuracy: 76.85%\n",
      "[23] loss: 0.56098 | accuracy: 78.85%\n",
      "[24] loss: 0.54496 | accuracy: 77.79%\n",
      "[25] loss: 0.52900 | accuracy: 79.15%\n",
      "[26] loss: 0.50955 | accuracy: 79.96%\n",
      "[27] loss: 0.49567 | accuracy: 79.46%\n",
      "[28] loss: 0.48135 | accuracy: 80.22%\n",
      "[29] loss: 0.46579 | accuracy: 81.32%\n",
      "[30] loss: 0.45377 | accuracy: 81.12%\n",
      "[31] loss: 0.43494 | accuracy: 82.37%\n",
      "[32] loss: 0.42655 | accuracy: 82.59%\n",
      "[33] loss: 0.41447 | accuracy: 81.66%\n",
      "[34] loss: 0.39797 | accuracy: 81.78%\n",
      "[35] loss: 0.38859 | accuracy: 81.87%\n",
      "[36] loss: 0.37761 | accuracy: 83.01%\n",
      "[37] loss: 0.36323 | accuracy: 83.79%\n",
      "[38] loss: 0.35409 | accuracy: 83.27%\n",
      "[39] loss: 0.33905 | accuracy: 83.45%\n",
      "[40] loss: 0.32926 | accuracy: 83.75%\n",
      "[41] loss: 0.32098 | accuracy: 83.86%\n",
      "[42] loss: 0.30963 | accuracy: 83.95%\n",
      "[43] loss: 0.29861 | accuracy: 84.10%\n",
      "[44] loss: 0.29032 | accuracy: 83.99%\n",
      "[45] loss: 0.28220 | accuracy: 84.09%\n",
      "[46] loss: 0.27148 | accuracy: 84.13%\n",
      "[47] loss: 0.27092 | accuracy: 84.19%\n",
      "[48] loss: 0.25817 | accuracy: 84.08%\n",
      "[49] loss: 0.24537 | accuracy: 84.27%\n",
      "[50] loss: 0.24140 | accuracy: 84.67%\n",
      "[51] loss: 0.22997 | accuracy: 84.44%\n",
      "[52] loss: 0.23494 | accuracy: 84.40%\n",
      "[53] loss: 0.22200 | accuracy: 84.49%\n",
      "[54] loss: 0.21121 | accuracy: 84.97%\n",
      "[55] loss: 0.20963 | accuracy: 84.60%\n",
      "[56] loss: 0.20162 | accuracy: 84.62%\n",
      "[57] loss: 0.19284 | accuracy: 85.32%\n",
      "[58] loss: 0.19010 | accuracy: 84.94%\n",
      "[59] loss: 0.18732 | accuracy: 85.29%\n",
      "[60] loss: 0.17839 | accuracy: 85.10%\n",
      "[61] loss: 0.17331 | accuracy: 85.17%\n",
      "[62] loss: 0.17124 | accuracy: 85.24%\n",
      "[63] loss: 0.16809 | accuracy: 85.55%\n",
      "[64] loss: 0.16460 | accuracy: 85.21%\n",
      "[65] loss: 0.15028 | accuracy: 85.53%\n",
      "[66] loss: 0.14868 | accuracy: 85.34%\n",
      "[67] loss: 0.14903 | accuracy: 85.67%\n",
      "[68] loss: 0.14767 | accuracy: 85.59%\n",
      "[69] loss: 0.13994 | accuracy: 85.44%\n",
      "[70] loss: 0.13785 | accuracy: 85.31%\n",
      "[71] loss: 0.13486 | accuracy: 85.32%\n",
      "[72] loss: 0.13288 | accuracy: 85.79%\n",
      "[73] loss: 0.13448 | accuracy: 85.51%\n",
      "[74] loss: 0.12621 | accuracy: 85.98%\n",
      "[75] loss: 0.12477 | accuracy: 85.78%\n",
      "[76] loss: 0.12148 | accuracy: 85.71%\n",
      "[77] loss: 0.12192 | accuracy: 86.19%\n",
      "[78] loss: 0.11402 | accuracy: 85.74%\n",
      "[79] loss: 0.11126 | accuracy: 85.63%\n",
      "[80] loss: 0.11159 | accuracy: 86.21%\n",
      "[81] loss: 0.10771 | accuracy: 85.67%\n",
      "[82] loss: 0.10719 | accuracy: 85.68%\n",
      "[83] loss: 0.10341 | accuracy: 85.35%\n",
      "[84] loss: 0.10471 | accuracy: 85.73%\n",
      "[85] loss: 0.10002 | accuracy: 86.00%\n",
      "[86] loss: 0.09742 | accuracy: 85.85%\n",
      "[87] loss: 0.09500 | accuracy: 85.77%\n",
      "[88] loss: 0.10063 | accuracy: 86.02%\n",
      "[89] loss: 0.09182 | accuracy: 85.87%\n",
      "[90] loss: 0.09402 | accuracy: 85.68%\n",
      "[91] loss: 0.09266 | accuracy: 86.02%\n",
      "[92] loss: 0.09095 | accuracy: 85.90%\n",
      "[93] loss: 0.08810 | accuracy: 86.27%\n",
      "[94] loss: 0.08419 | accuracy: 85.63%\n",
      "[95] loss: 0.08151 | accuracy: 85.68%\n",
      "[96] loss: 0.08063 | accuracy: 86.00%\n",
      "[97] loss: 0.07976 | accuracy: 86.12%\n",
      "[98] loss: 0.08270 | accuracy: 86.06%\n",
      "[99] loss: 0.08037 | accuracy: 85.81%\n",
      "[100] loss: 0.07862 | accuracy: 86.11%\n",
      "=== Finished: 3 | sgd ===\n",
      "\\Baseline accuracy on test: 86.11 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BASELINE_ACC = train_baseline(coef=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in (0, 0.1, 0.5, 0.7, 0.9):\n",
    "    for opt in (\"sgd\", \"adam\"):\n",
    "        distil(a=a, kind=3, opt=opt, coef=1)"
   ]
  }
 ]
}