{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('hse_ml')","metadata":{"interpreter":{"hash":"52f65c1dba17a6893288d8494a539e55e57ab164b424d6c977bf5446fbca9423"}}},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"colab":{"name":"hw09_task.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"1PjQglGj4q54"},"source":["# Случайные леса\n","__Суммарное количество баллов: 10__\n","\n","__Решение отправлять на `ml.course.practice@gmail.com`__\n","\n","__Тема письма: `[ML][MS][HW09] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n","\n","В этом задании вам предстоит реализовать ансамбль деревьев решений, известный как случайный лес, применить его к публичным данным пользователей социальной сети Вконтакте, и сравнить его эффективность с ансамблем, предоставляемым библиотекой CatBoost.\n","\n","В результате мы сможем определить, какие подписки пользователей больше всего влияют на определение возраста и пола человека. "]},{"cell_type":"code","metadata":{"id":"LH5PiGz04q5-"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","import numpy as np\n","import pandas\n","import random\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import copy\n","from catboost import CatBoostClassifier\n","from typing import Callable, Union, NoReturn, Optional, Dict, Any, List"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"bQUJHTjS4q5-"},"source":["def gini(x):\n","    _, counts = np.unique(x, return_counts=True)\n","    proba = counts / len(x)\n","    return np.sum(proba * (1 - proba))\n","    \n","def entropy(x):\n","    _, counts = np.unique(x, return_counts=True)\n","    proba = counts / len(x)\n","    return -np.sum(proba * np.log2(proba))\n","\n","def gain(left_y, right_y, criterion):\n","    y = np.concatenate((left_y, right_y))\n","    return criterion(y) - (criterion(left_y) * len(left_y) + criterion(right_y) * len(right_y)) / len(y)\n","\n","def bagging(X, y):\n","    ids = np.arange(X.shape[0])\n","    ids_in_bag = np.random.choice(ids, size=(X.shape[0]))\n","    ids_oob = ids[~np.in1d(ids, ids_in_bag)]\n","    return (X[ids_in_bag], y[ids_in_bag]), (X[ids_oob], y[ids_oob])"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tfxycK0Q4q5_"},"source":["### Задание 1 (2 балла)\n","Random Forest состоит из деревьев решений. Каждое такое дерево строится на одной из выборок, полученных при помощи bagging. Элементы, которые не вошли в новую обучающую выборку, образуют out-of-bag выборку. Кроме того, в каждом узле дерева мы случайным образом выбираем набор из `max_features` и ищем признак для предиката разбиения только в этом наборе.\n","\n","Сегодня мы будем работать только с бинарными признаками, поэтому нет необходимости выбирать значение признака для разбиения.\n","\n","#### Методы\n","`predict(X)` - возвращает предсказанные метки для элементов выборки `X`\n","\n","#### Параметры конструктора\n","`X, y` - обучающая выборка и соответствующие ей метки классов. Из нее нужно получить выборку для построения дерева при помощи bagging. Out-of-bag выборку нужно запомнить, она понадобится потом.\n","\n","`criterion=\"gini\"` - задает критерий, который будет использоваться при построении дерева. Возможные значения: `\"gini\"`, `\"entropy\"`.\n","\n","`max_depth=None` - ограничение глубины дерева. Если `None` - глубина не ограничена\n","\n","`min_samples_leaf=1` - минимальное количество элементов в каждом листе дерева.\n","\n","`max_features=\"auto\"` - количество признаков, которые могут использоваться в узле. Если `\"auto\"` - равно `sqrt(X.shape[1])`"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class DecisionTreeLeaf:\n","    \"\"\"\n","    Attributes\n","    ----------\n","    y : dict\n","        Словарь, отображающий метки в вероятность того, что объект, попавший в данный лист, принадлежит классу, соответствующиему метке \n","    \"\"\"\n","    def __init__(self, labels):\n","        ulabels, cnts = np.unique(labels, return_counts=True)\n","        self.y = ulabels[np.argmax(cnts)]\n","        cnts = np.array(cnts, dtype=np.float)\n","        cnts /= labels.shape[0]\n","\n","        self.dict = {label: prob for label, prob in zip(ulabels, cnts)}\n","\n","\n","class DecisionTreeNode:\n","    \"\"\"\n","\n","    Attributes\n","    ----------\n","    split_dim : int\n","        Измерение, по которому разбиваем выборку.\n","    split_value : float\n","        Значение, по которому разбираем выборку.\n","    left : Union[DecisionTreeNode, DecisionTreeLeaf]\n","        Поддерево, отвечающее за случай x[split_dim] < split_value.\n","    right : Union[DecisionTreeNode, DecisionTreeLeaf]\n","        Поддерево, отвечающее за случай x[split_dim] >= split_value. \n","    \"\"\"\n","    def __init__(self, split_dim: int, split_value: float, \n","                 left: Union['DecisionTreeNode', DecisionTreeLeaf], \n","                 right: Union['DecisionTreeNode', DecisionTreeLeaf]):\n","        self.split_dim = split_dim\n","        self.split_value = split_value\n","        self.left = left\n","        self.right = right"]},{"cell_type":"code","metadata":{"id":"8smLW2V_4q5_"},"source":["class DecisionTree:\n","    def __init__(self, X, y, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=\"auto\"):\n","        self.criterion = gini if criterion == \"gini\" else entropy\n","        self.max_depth = max_depth\n","        self.min_samples_leaf = min_samples_leaf\n","        self.max_features = np.floor(np.sqrt(X.shape[1])).astype(np.int) if max_features == \"auto\" else max_features\n","\n","        self.bag, self.oob = bagging(X, y)\n","\n","    def _step(self, X, y, depth: int = 0):\n","        if self.max_depth is not None and depth >= self.max_depth:\n","            return DecisionTreeLeaf(y)\n","        is_leaf = True\n","        gain2max = 0\n","        for feature in np.random.choice(X.shape[1], size=self.max_features, replace=False):\n","            potential_values = np.unique(X[:, feature])\n","            for value in potential_values:\n","                left = X[:, feature] == 0\n","                right = ~left\n","                left_node_size = np.sum(left)\n","                right_node_size = X.shape[0] - left_node_size\n","                cur_gain = gain(y[left], y[right], self.criterion)\n","\n","                if cur_gain >= gain2max and left_node_size >= self.min_samples_leaf and right_node_size >= self.min_samples_leaf:\n","                    is_leaf = False\n","                    gain2max = cur_gain\n","                    feature2split = feature\n","                    value2split = value\n","                    left_node = left.copy()\n","                    right_node = right.copy()\n","                    \n","        return DecisionTreeLeaf(y) if is_leaf else DecisionTreeNode(feature2split, \n","                                                                    value2split, \n","                                                                    self._step(X[left_node], y[left_node], depth + 1), \n","                                                                    self._step(X[right_node], y[right_node], depth + 1))\n","\n","\n","    def fit(self):\n","        X, y = self.bag\n","        self.root = self._step(X, y)\n","\n","    def _split(self, x, node: DecisionTreeNode):\n","        val = node.split_value\n","        idx = node.split_dim\n","\n","        if x[idx] < val:\n","            return node.left\n","        else:\n","            return node.right\n","\n","    def dive(self, x, node):\n","        if isinstance(node, DecisionTreeLeaf):\n","            return node.dict\n","        return self.dive(x, self._split(x, node))\n","\n","    def get_acc(self, X, y):\n","        return np.sum(self.predict(X) != y) / y.shape[0]\n","\n","    def get_error(self, X, y):\n","        return 1 - self.get_acc(X, y)\n","\n","    def predict_proba(self, X: np.ndarray) ->  List[Dict[Any, float]]:\n","        \"\"\"\n","        Предсказывает вероятность классов для элементов из X.\n","\n","        Parameters\n","        ----------\n","        X : np.ndarray\n","            Элементы для предсказания.\n","        \n","        Return\n","        ------\n","        List[Dict[Any, float]]\n","            Для каждого элемента из X возвращает словарь \n","            {метка класса -> вероятность класса}.\n","        \"\"\"\n","        out = []\n","        for x in X:\n","            out.append(self.dive(x, self.root))\n","        return out\n","\n","    def predict(self, X):\n","        return np.array([max(p.keys(), key=lambda k: p[k]) for p in self.predict_proba(X)], dtype=np.int)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9oijgwLt4q6A"},"source":["### Задание 2 (2 балла)\n","Теперь реализуем сам Random Forest. Идея очень простая: строим `n` деревьев, а затем берем модальное предсказание.\n","\n","#### Параметры конструктора\n","`n_estimators` - количество используемых для предсказания деревьев.\n","\n","Остальное - параметры деревьев.\n","\n","#### Методы\n","`fit(X, y)` - строит `n_estimators` деревьев по выборке `X`.\n","\n","`predict(X)` - для каждого элемента выборки `X` возвращает самый частый класс, который предсказывают для него деревья."]},{"cell_type":"code","metadata":{"id":"APIy88YW4q6A"},"source":["class RandomForestClassifier:\n","    def __init__(self, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=\"auto\", n_estimators=10):\n","        self.criterion = gini if criterion == \"gini\" else entropy\n","        self.max_depth = max_depth\n","        self.min_samples_leaf = min_samples_leaf\n","        self.max_features = max_features\n","        self.n_estimators = n_estimators\n","        self.estsimators = []\n","    \n","    def fit(self, X, y):\n","        for _ in range(self.n_estimators):\n","            dt_ = DecisionTree(X, y, criterion=self.criterion, \n","                               max_depth=self.max_depth, \n","                               min_samples_leaf=self.min_samples_leaf, \n","                               max_features=self.max_features)\n","            dt_.fit()\n","            self.estsimators.append(dt_)\n","    \n","    def predict(self, X):\n","        predictions = np.zeros((self.n_estimators, X.shape[0]), dtype=int)\n","        for i, dt in enumerate(self.estsimators):\n","            predictions[i] = dt.predict(X)\n","\n","        out = np.zeros(X.shape[0])\n","        for i, pred in enumerate(predictions.T):\n","            out[i] = np.bincount(pred).argmax()\n","        return out\n","\n","\n","    def get_feature_importance(self):\n","        num_features = self.estsimators[0].oob[0].shape[1]\n","        out = np.zeros((self.n_estimators, num_features))\n","        for i, dt in enumerate(self.estsimators):\n","            oob_acc = dt.get_error(dt.oob[0], dt.oob[1])\n","            for j in range(num_features):\n","                shuffled_ids = np.random.permutation(range(dt.oob[0].shape[0]))\n","                X_ = dt.oob[0].copy()\n","                X_[:, j] = X_[shuffled_ids, j]\n","\n","                out[i, j] = oob_acc - dt.get_error(X_, dt.oob[1])\n","        return np.mean(out, axis=0)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i80pffMn4q6A"},"source":["### Задание 3 (2 балла)\n","Часто хочется понимать, насколько большую роль играет тот или иной признак для предсказания класса объекта. Есть различные способы посчитать его важность. Один из простых способов сделать это для Random Forest - посчитать out-of-bag ошибку предсказания `err_oob`, а затем перемешать значения признака `j` и посчитать ее (`err_oob_j`) еще раз. Оценкой важности признака `j` для одного дерева будет разность `err_oob_j - err_oob`, важность для всего леса считается как среднее значение важности по деревьям.\n","\n","Реализуйте функцию `feature_importance`, которая принимает на вход Random Forest и возвращает массив, в котором содержится важность для каждого признака."]},{"cell_type":"code","metadata":{"id":"rEmVG1Fl4q6B"},"source":["def feature_importance(rfc):\n","    return rfc.get_feature_importance()\n","\n","def most_important_features(importance, names, k=20):\n","    # Выводит названия k самых важных признаков\n","    idicies = np.argsort(importance)[::-1][:k]\n","    return np.array(names)[idicies]"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JooN_YKm4q6B"},"source":["Наконец, пришло время протестировать наше дерево на простом синтетическом наборе данных. В результате точность должна быть примерно равна `1.0`, наибольшее значение важности должно быть у признака с индексом `4`, признаки с индексами `2` и `3`  должны быть одинаково важны, а остальные признаки - не важны совсем."]},{"cell_type":"code","metadata":{"id":"8gqYMp994q6B"},"source":["def synthetic_dataset(size):\n","    X = [(np.random.randint(0, 2), np.random.randint(0, 2), i % 6 == 3, \n","          i % 6 == 0, i % 3 == 2, np.random.randint(0, 2)) for i in range(size)]\n","    y = [i % 3 for i in range(size)]\n","    return np.array(X), np.array(y)\n","\n","X, y = synthetic_dataset(1000)\n","rfc = RandomForestClassifier(n_estimators=100)\n","rfc.fit(X, y)\n","print(\"Accuracy:\", np.mean(rfc.predict(X) == y))\n","print(\"Importance:\", feature_importance(rfc))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0\n","Importance: [2.94407686e-05 2.20079884e-03 1.69027520e-01 1.69024412e-01\n"," 3.19102449e-01 2.43177305e-03]\n"]}]},{"cell_type":"markdown","metadata":{"id":"vRtGOs164q6C"},"source":["### Задание 4 (1 балл)\n","Теперь поработаем с реальными данными.\n","\n","Выборка состоит из публичных анонимизированных данных пользователей социальной сети Вконтакте. Первые два столбца отражают возрастную группу (`zoomer`, `doomer` и `boomer`) и пол (`female`, `male`). Все остальные столбцы являются бинарными признаками, каждый из них определяет, подписан ли пользователь на определенную группу/публичную страницу или нет.\\\n","\\\n","Необходимо обучить два классификатора, один из которых определяет возрастную группу, а второй - пол.\\\n","\\\n","Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются. Лес должен строиться за какое-то разумное время."]},{"cell_type":"code","metadata":{"id":"HruobK-q4q6C"},"source":["def read_dataset(path):\n","    dataframe = pandas.read_csv(path, header=0)\n","    dataset = dataframe.values.tolist()\n","    random.shuffle(dataset)\n","    y_age = [row[0] for row in dataset]\n","    y_sex = [row[1] for row in dataset]\n","    X = [row[2:] for row in dataset]\n","    \n","    return np.array(X), np.array(y_age), np.array(y_sex), list(dataframe.columns)[2:]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"K0QXWr3b4q6C"},"source":["X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n","y_age = preprocessing.LabelEncoder().fit_transform(y_age)\n","y_sex = preprocessing.LabelEncoder().fit_transform(y_sex)\n","X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I0y8J97m4q6C"},"source":["#### Возраст"]},{"cell_type":"code","metadata":{"id":"MLJykJZH4q6C"},"source":["rfc = RandomForestClassifier(n_estimators=10)\n","\n","rfc.fit(X_train, y_age_train)\n","print(\"Accuracy:\", np.mean(rfc.predict(X_test) == y_age_test))\n","print(\"Most important features:\")\n","for i, name in enumerate(most_important_features(feature_importance(rfc), features, 20)):\n","    print(str(i + 1) + \".\", name)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.691046658259773\n","Most important features:\n","1. rhymes\n","2. 4ch\n","3. styd.pozor\n","4. ovsyanochan\n","5. mudakoff\n","6. dayvinchik\n","7. pravdashowtop\n","8. tumblr_vacuum\n","9. iwantyou\n","10. rapnewrap\n","11. pixel_stickers\n","12. ne1party\n","13. bot_maxim\n","14. bestad\n","15. fuck_humor\n","16. i_des\n","17. memeboizz\n","18. pozor\n","19. girlmeme\n","20. bog_memes\n"]}]},{"cell_type":"markdown","metadata":{"id":"cgNpaAKH4q6D"},"source":["#### Пол"]},{"cell_type":"code","metadata":{"id":"X-zne5-R4q6D"},"source":["rfc = RandomForestClassifier(n_estimators=10)\n","rfc.fit(X_train, y_sex_train)\n","print(\"Accuracy:\", np.mean(rfc.predict(X_test) == y_sex_test))\n","print(\"Most important features:\")\n","for i, name in enumerate(most_important_features(feature_importance(rfc), features, 20)):\n","    print(str(i + 1) + \".\", name)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8638083228247163\n","Most important features:\n","1. 40kg\n","2. zerofat\n","3. mudakoff\n","4. modnailru\n","5. girlmeme\n","6. be.beauty\n","7. 9o_6o_9o\n","8. sh.cook\n","9. beauty\n","10. be.women\n","11. i_d_t\n","12. reflexia_our_feelings\n","13. woman.blog\n","14. femalemem\n","15. igm\n","16. thesmolny\n","17. cook_good\n","18. rapnewrap\n","19. 4ch\n","20. recipes40kg\n"]}]},{"cell_type":"markdown","metadata":{"id":"pxeTQylQ4q6D"},"source":["### CatBoost\n","В качестве альтернативы попробуем CatBoost. \n","\n","Установить его можно просто с помощью `pip install catboost`. Туториалы можно найти, например, [здесь](https://catboost.ai/docs/concepts/python-usages-examples.html#multiclassification) и [здесь](https://github.com/catboost/tutorials/blob/master/python_tutorial.ipynb). Главное - не забудьте использовать `loss_function='MultiClass'`.\\\n","\\\n","Сначала протестируйте CatBoost на синтетических данных. Выведите точность и важность признаков."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["X, y = synthetic_dataset(1000)\n","X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8, random_state=42)"]},{"cell_type":"code","metadata":{"id":"DOqVkEnd4q6D"},"source":["rfc = CatBoostClassifier(\n","    custom_loss=['Accuracy'],\n","    random_seed=42,\n","    logging_level='Silent',\n","    loss_function='MultiClass'\n",")\n","\n","rfc.fit(\n","    X_train, y_train,\n","    eval_set=(X_validation, y_validation),\n",")"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<catboost.core.CatBoostClassifier at 0x7f268155aac0>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0\nImportance: [8.76700807e-03 6.18909182e-03 2.92537392e+01 2.73267033e+01\n 4.34027323e+01 1.86915561e-03]\n"]}],"source":["print(\"Accuracy:\", np.mean(rfc.predict(X_validation).flatten() == y_validation))\n","print(\"Importance:\", feature_importance(rfc))"]},{"cell_type":"markdown","metadata":{"id":"tcLRsSNG4q6E"},"source":["### Задание 5 (3 балла)\n","Попробуем применить один из используемых на практике алгоритмов. В этом нам поможет CatBoost. Также, как и реализованный ними RandomForest, применим его для определения пола и возраста пользователей сети Вконтакте, выведите названия наиболее важных признаков так же, как в задании 3.\\\n","\\\n","Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются."]},{"cell_type":"code","metadata":{"id":"hJGrQcO-4q6E"},"source":["X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n","X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)\n","X_train, X_eval, y_age_train, y_age_eval, y_sex_train, y_sex_eval = train_test_split(X_train, y_age_train, y_sex_train, train_size=0.8)"],"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["rfc = CatBoostClassifier(\n","    custom_loss=['Accuracy'],\n","    random_seed=42,\n","    logging_level='Silent',\n","    loss_function='MultiClass'\n",")"]},{"cell_type":"markdown","metadata":{"id":"XA5f_8eC4q6E"},"source":["#### Возраст"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<catboost.core.CatBoostClassifier at 0x7f268148ec70>"]},"metadata":{},"execution_count":17}],"source":["rfc.fit(\n","    X_train, y_age_train,\n","    eval_set=(X_eval, y_age_eval),\n",")"]},{"cell_type":"code","metadata":{"id":"qSeUpxPj4q6E"},"source":["print(\"Accuracy:\", np.mean(rfc.predict(X_test).flatten() == y_age_test))\n","print(\"Most important features:\")\n","for i, name in enumerate(most_important_features(feature_importance(rfc), features, 10)):\n","    print(str(i+1) + \".\", name)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7528373266078184\nMost important features:\n1. ovsyanochan\n2. styd.pozor\n3. 4ch\n4. leprum\n5. mudakoff\n6. dayvinchik\n7. rhymes\n8. xfilm\n9. fuck_humor\n10. iwantyou\n"]}]},{"cell_type":"markdown","metadata":{"id":"KfYSptm74q6E"},"source":["#### Пол"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<catboost.core.CatBoostClassifier at 0x7f268148ec70>"]},"metadata":{},"execution_count":19}],"source":["rfc.fit(\n","    X_train, y_sex_train,\n","    eval_set=(X_eval, y_sex_eval),\n",")"]},{"cell_type":"code","metadata":{"id":"4rKa-f6F4q6E"},"source":["print(\"Accuracy:\", np.mean(rfc.predict(X_test).flatten() == y_sex_test))\n","print(\"Most important features:\")\n","for i, name in enumerate(most_important_features(feature_importance(rfc), features, 10)):\n","    print(str(i+1) + \".\", name)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8701134930643127\nMost important features:\n1. 40kg\n2. mudakoff\n3. modnailru\n4. girlmeme\n5. igm\n6. academyofman\n7. 4ch\n8. zerofat\n9. i_d_t\n10. femalemem\n"]}]}]}