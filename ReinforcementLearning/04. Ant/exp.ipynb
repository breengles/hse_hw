{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('hse_ml')",
   "metadata": {
    "interpreter": {
     "hash": "52f65c1dba17a6893288d8494a539e55e57ab164b424d6c977bf5446fbca9423"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet_envs\n",
    "from gym import make\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Normal\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "import random\n",
    "from itertools import product\n",
    "import joblib\n",
    "from os import makedirs\n",
    "import uuid\n",
    "from train import *\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import combinations, product, permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(env_name=\"AntBulletEnv-v0\", \n",
    "        transitions=1000000, \n",
    "        eps=0.2, \n",
    "        gamma=0.99, \n",
    "        tau=0.002, \n",
    "        actor_lr=2e-4, \n",
    "        critic_lr=5e-4, \n",
    "        sigma=2, \n",
    "        c=1, \n",
    "        updates_number=1, \n",
    "        policy_delay=1, \n",
    "        batch_size=128):\n",
    "    log = {\n",
    "        \"cfg\": {\n",
    "            \"transitions\": transitions,\n",
    "            \"eps\": eps,\n",
    "            \"gamma\": gamma,\n",
    "            \"tau\": tau,\n",
    "            \"actor_lr\": actor_lr,\n",
    "            \"critic_lr\": critic_lr,\n",
    "            \"sigma\": sigma,\n",
    "            \"c\": c,\n",
    "            \"updates_number\": updates_number,\n",
    "            \"policy_delay\": policy_delay,\n",
    "            \"batch_size\": batch_size\n",
    "        },\n",
    "        \"step\": [],\n",
    "        \"rmean\": [],\n",
    "        \"rstd\": []\n",
    "    }\n",
    "\n",
    "    makedirs(\"experiments\", exist_ok=True)\n",
    "    saved_agent_dir = \"experiments/\" + str(uuid.uuid4())\n",
    "    makedirs(saved_agent_dir)\n",
    "    with open(f\"{saved_agent_dir}/params.json\", \"w\") as param:\n",
    "        json.dump(log[\"cfg\"], param, indent=4)\n",
    "    log_file = open(f\"{saved_agent_dir}/log\", \"a\")\n",
    "\n",
    "    env = make(env_name)\n",
    "    test_env = make(env_name)\n",
    "    \n",
    "    td3 = TD3(state_dim=env.observation_space.shape[0], \n",
    "              action_dim=env.action_space.shape[0], \n",
    "              actor_lr=actor_lr, critic_lr=critic_lr)\n",
    "\n",
    "    state = env.reset()\n",
    "    episodes_sampled = 0\n",
    "    steps_sampled = 0\n",
    "    \n",
    "    for i in range(transitions):\n",
    "        action = td3.act(state)\n",
    "        action = np.clip(action + eps * np.random.randn(*action.shape), -1, +1)\n",
    "\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        td3.update((state, action, next_state, reward, done), \n",
    "                    sigma=sigma, c=c, updates_number=updates_number, policy_delay=policy_delay,\n",
    "                    batch_size=batch_size, gamma=gamma, tau= tau)\n",
    "        \n",
    "        state = env.reset() if done else next_state\n",
    "        \n",
    "        if (i + 1) % (transitions // 100) == 0:\n",
    "            rewards = evaluate_policy(test_env, td3, 50)\n",
    "            rmean = np.mean(rewards)\n",
    "            rstd = np.std(rewards)\n",
    "\n",
    "            log[\"step\"].append(i + 1)\n",
    "            log[\"rmean\"].append(rmean)\n",
    "            log[\"rstd\"].append(rstd)\n",
    "\n",
    "            log_file.write(f\"{i + 1},{rmean},{rstd}\\n\")\n",
    "            log_file.flush()\n",
    "            td3.save(name=f\"{saved_agent_dir}/{i + 1}_{int(rmean)}_{int(rstd)}.pkl\")\n",
    "    return log\n",
    "\n",
    "drun = delayed(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(log):\n",
    "    rmean = np.array(log[\"rmean\"])\n",
    "    rstd = np.array(log[\"rstd\"])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    cfg = log[\"cfg\"]\n",
    "    ax.set_title(f\"{cfg}\")\n",
    "    ax.set_xlabel(\"â„– of transitions\")\n",
    "    ax.set_ylabel(\"Mean reward\")\n",
    "\n",
    "    plt.hlines(2000, np.min(log[\"step\"]), np.max(log[\"step\"]),\n",
    "               colors=\"r\", label=\"Solved\")\n",
    "\n",
    "    plt.plot(log[\"step\"],\n",
    "             rmean,\n",
    "             label=\"TD3\")\n",
    "\n",
    "    plt.fill_between(log[\"step\"],\n",
    "                     rmean - rstd,\n",
    "                     rmean + rstd, alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config = {\n",
    "    \"transitions\": 1_000_000,\n",
    "    \"eps\": 0.2,\n",
    "    \"gamma\": 0.99,\n",
    "    \"tau\": 0.002,\n",
    "    \"actor_lr\": 2e-4,\n",
    "    \"critic_lr\": 5e-4,\n",
    "    \"sigma\": 2,\n",
    "    \"c\": 1,\n",
    "    \"updates_number\": 1,\n",
    "    \"policy_delay\": 1,\n",
    "    \"batch_size\": 128\n",
    "}\n",
    "\n",
    "configs = [base_config, base_config.copy(), base_config.copy(), base_config.copy(), base_config.copy(), base_config.copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps_lst = [0.01, 0.1, 0.3, 0.4, 0.5]\n",
    "# for idx, eps in enumerate(eps_lst):\n",
    "#     configs[idx + 1][\"eps\"] = eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logs = Parallel(n_jobs=6)(drun(**cfg) for cfg in configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for log in logs:\n",
    "#     plot(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "116640\n"
     ]
    }
   ],
   "source": [
    "configs = []\n",
    "\n",
    "params = product(\n",
    "    (3_000_000,),\n",
    "    (0.1, 0.2, 0.3, 0.4, 0.5),\n",
    "    (0.95, 0.99, 0.999),\n",
    "    (1e-4, 1e-3, 1e-2),\n",
    "    (1e-4, 2e-4, 1e-3),\n",
    "    (2e-4, 4e-4, 2e-3),\n",
    "    (0.5, 1, 2),\n",
    "    (0.5, 1, 2),\n",
    "    (1, 2, 4, 8),\n",
    "    (1, 2, 4, 8),\n",
    "    (64, 128),\n",
    ")\n",
    "\n",
    "for tramsitions, eps, gamma, tau, actor_lr, critic_lr, sigma, c, updates_number, policy_delay, batch_size in params:\n",
    "    configs.append({\n",
    "        \"transitions\": tramsitions,\n",
    "        \"eps\": eps,\n",
    "        \"gamma\": gamma,\n",
    "        \"tau\": tau,\n",
    "        \"actor_lr\": actor_lr,\n",
    "        \"critic_lr\": critic_lr,\n",
    "        \"sigma\": sigma,\n",
    "        \"c\": c,\n",
    "        \"updates_number\": updates_number,\n",
    "        \"policy_delay\": policy_delay,\n",
    "        \"batch_size\": batch_size\n",
    "    })\n",
    "\n",
    "print(len(configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "logs = Parallel(n_jobs=6)(drun(**cfg) for cfg in configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in logs:\n",
    "    plot(log)"
   ]
  }
 ]
}